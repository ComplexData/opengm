#ifndef SELF_FUSION_PARAM
#define SELF_FUSION_PARAM

#include "param_exporter_base.hxx"
//solver specific
#include <opengm/inference/self_fusion.hxx>

using namespace boost::python;

template<class INFERENCE>
class InfParamExporterSelfFusion{

public:
   typedef typename INFERENCE::ValueType ValueType;
   typedef typename INFERENCE::Parameter Parameter;
   typedef InfParamExporterSelfFusion<INFERENCE> SelfType;
   typedef typename  INFERENCE::ToFuseInferenceType ToFuseInferenceType;
   typedef typename ToFuseInferenceType::Parameter ToFuseInferenceParameter;


   inline static void set 
   (
      Parameter & p,
      const opengm::UInt64Type fuseNth,
      const typename INFERENCE::FusionSolver fusionSolver,
      const ToFuseInferenceParameter & infParam,
      const opengm::UInt64Type maxSubgraphSize
   ) {
      p.fuseNth_=fuseNth;
      p.fusionSolver_=fusionSolver;
      p.infParam_=infParam;
      p.maxSubgraphSize_=maxSubgraphSize;
   } 

   void static exportInfParam(const std::string & className){
      class_<Parameter > ( className.c_str() , init< > ())
      .def_readwrite("fuseNth", &Parameter::fuseNth_,
         "fuse each nth label generated by toFuseInf infence solver")
      .def_readwrite("fusionSolver", &Parameter::fusionSolver_,
         "fusionSolver can be:\n\n"
         "  -``'qpbo_fusion'`` : qpbo fusion (default)\n\n"
         "  -``'ad3_fusion'`` : ad3 fusion \n\n"
         "  -``'astar_fusion'`` : astar fusion (broken???)\n\n"
         "  -``'lazy_flipper_fusion'`` : lazy flipper fusion \n\n"
         "  -``'cplex_fusion '`` : cplex flipper fusion \n\n"
      )
      .def_readwrite("infParam", &Parameter::infParam_,
         "fuse each nth label generated by toFuseInf infence solver")
      .def_readwrite("maxSubgraphSize", &Parameter::maxSubgraphSize_,
         "max subgraph size if lazy flipper is used as fusion move solver")

      .def ("set", &SelfType::set, 
         (
            boost::python::arg("fuseNth")=1,
            boost::python::arg("fusionSolver")=INFERENCE::LazyFlipperFusion,
            boost::python::arg("infParam")=ToFuseInferenceParameter(),
            boost::python::arg("maxSubgraphSize")=2
         ) 
      )
   ;
   }
};

template<class INF>
class InfParamExporter<opengm::SelfFusion< INF > >  : public  InfParamExporterSelfFusion<opengm::SelfFusion< INF > > {

};

#endif